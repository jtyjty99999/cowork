# ================================
# AI 大模型配置示例
# ================================
# 
# 使用说明：
# 1. 复制此文件为 .env.local
#    命令：cp .env.local.example .env.local
# 
# 2. 填入你的真实 API Key
# 
# 3. 设置 NEXT_PUBLIC_USE_REAL_AI=true 启用真实 AI
# 
# 4. 重启开发服务器
#    命令：npm run dev
# 
# 详细配置指南请查看：AI_SETUP.md
# ================================

# ================================
# 基础配置
# ================================

# 是否使用真实 AI（true=真实API, false=模拟响应）
NEXT_PUBLIC_USE_REAL_AI=false

# 默认使用的模型
NEXT_PUBLIC_DEFAULT_MODEL=gpt-4

# ================================
# OpenAI 配置（推荐）
# ================================
# 获取 API Key: https://platform.openai.com/api-keys
# 
# 可用模型：
# - gpt-4 (最强大)
# - gpt-4-turbo (更快)
# - gpt-3.5-turbo (经济实惠)

NEXT_PUBLIC_OPENAI_API_KEY=sk-your-openai-api-key-here
NEXT_PUBLIC_OPENAI_BASE_URL=https://api.openai.com/v1

# ================================
# Anthropic Claude 配置
# ================================
# 获取 API Key: https://console.anthropic.com/
# 
# 可用模型：
# - claude-3-opus-20240229 (最强大)
# - claude-3-sonnet-20240229 (平衡)
# - claude-3-haiku-20240307 (快速)

# NEXT_PUBLIC_ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here
# NEXT_PUBLIC_ANTHROPIC_BASE_URL=https://api.anthropic.com

# ================================
# 国内 AI 服务配置
# ================================

# 阿里云通义千问
# 获取 API Key: https://dashscope.console.aliyun.com/
# NEXT_PUBLIC_OPENAI_API_KEY=sk-your-qwen-api-key
# NEXT_PUBLIC_OPENAI_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
# NEXT_PUBLIC_DEFAULT_MODEL=qwen-turbo

# 智谱 AI (GLM)
# 获取 API Key: https://open.bigmodel.cn/
# NEXT_PUBLIC_OPENAI_API_KEY=your-glm-api-key
# NEXT_PUBLIC_OPENAI_BASE_URL=https://open.bigmodel.cn/api/paas/v4
# NEXT_PUBLIC_DEFAULT_MODEL=glm-4

# 百度文心一言
# 获取 API Key: https://console.bce.baidu.com/qianfan/
# NEXT_PUBLIC_OPENAI_API_KEY=your-ernie-api-key
# NEXT_PUBLIC_OPENAI_BASE_URL=https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop
# NEXT_PUBLIC_DEFAULT_MODEL=ernie-bot-4

# ================================
# 本地部署模型（Ollama）
# ================================
# 安装 Ollama: https://ollama.ai/
# 启动服务: ollama serve
# 
# NEXT_PUBLIC_OPENAI_API_KEY=ollama
# NEXT_PUBLIC_OPENAI_BASE_URL=http://localhost:11434/v1
# NEXT_PUBLIC_DEFAULT_MODEL=llama2

# ================================
# 高级配置
# ================================

# API 请求超时时间（毫秒）
# NEXT_PUBLIC_API_TIMEOUT=30000

# 最大重试次数
# NEXT_PUBLIC_MAX_RETRIES=3

# 是否启用流式响应
# NEXT_PUBLIC_ENABLE_STREAMING=false
